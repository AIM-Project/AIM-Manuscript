{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code used for implementing the classifer in paper Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring.\n",
    "\n",
    "**Data Set**: Raw/original data used in the Golub etc. paper. \n",
    "    - Train Data: 38 bone marrow samples(27ALL, 11AML).\n",
    "    - Test Data: 34 samples(24 bone marrow, 10 peripheral blood samples, 20ALL, 14AML).\n",
    "    - Predictors: 7129 gene expression levels represent 6817 genes.\n",
    "    \n",
    "**Main Purpose**: Golub Classifier: class prediction, using the built classifiers to predict the class of a new tumor sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce using R\n",
    "\n",
    "Most of the steps below strictly follow the procedures in the class prediction part in the Golub Paper and we get highly resemble result as in the paper. To reproduce the reproduced result, a seed is set in step 2 below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Load and transform dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _**Step 1(a)**_: Install Bioconductor biocLite package in order to access the golubEsets library. [golubEsets](https://bioconductor.org/packages/release/data/experiment/manuals/golubEsets/man/golubEsets.pdf) contains the raw data used by Todd Golub in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Most code is commented in this cell since it is unnecessary and time-consuming to run it everytime.\n",
    "# options(repos='http://cran.rstudio.com/') \n",
    "# source(\"http://bioconductor.org/biocLite.R\")\n",
    "# biocLite(\"golubEsets\")\n",
    "suppressMessages(library(golubEsets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Step 1(b)**_: Load the training, testing data from library golubEsets. Also transpose the data to make observations as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Train</th><td>38  </td><td>7129</td></tr>\n",
       "\t<tr><th scope=row>Test</th><td>34  </td><td>7129</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "\tTrain & 38   & 7129\\\\\n",
       "\tTest & 34   & 7129\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Train | 38   | 7129 | \n",
       "| Test | 34   | 7129 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1] [,2]\n",
       "Train 38   7129\n",
       "Test  34   7129"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Train</th><th scope=col>Test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>ALL</th><td>27</td><td>20</td></tr>\n",
       "\t<tr><th scope=row>AML</th><td>11</td><td>14</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & Train & Test\\\\\n",
       "\\hline\n",
       "\tALL & 27 & 20\\\\\n",
       "\tAML & 11 & 14\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Train | Test | \n",
       "|---|---|\n",
       "| ALL | 27 | 20 | \n",
       "| AML | 11 | 14 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    Train Test\n",
       "ALL 27    20  \n",
       "AML 11    14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training data predictor and response\n",
    "data(Golub_Train)\n",
    "golub_train_p = t(exprs(Golub_Train))\n",
    "golub_train_r =pData(Golub_Train)[, \"ALL.AML\"]\n",
    "#Testing data predictor\n",
    "data(Golub_Test)\n",
    "golub_test_p = t(exprs(Golub_Test))\n",
    "golub_test_r = pData(Golub_Test)[, \"ALL.AML\"]\n",
    "#Show summary\n",
    "rbind(Train = dim(golub_train_p), Test = dim(golub_test_p))\n",
    "cbind(Train = table(golub_train_r),Test = table(golub_test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Step 1(c)**_: Perform data preprocessing: thresholding, filtering, logarithmic transformation and normalization as in the paper. The predictor is reduced to 3051 after preprocessing.\n",
    "\n",
    "Most details of step 1(c) are not included in the original paper. We combine the information in paper 2, paper 9 and also a reproduce work done by [Robert Gentleman](http://dept.stat.lsa.umich.edu/~ionides/810/gentleman05.pdf), who confirmed in his work the procedure of thresholding and filtering is the same as in the original paper. One also need to notice that we should use the mean and standard deviation in the training data to normalize the testing data as mentioned in the Appendix A of the paper 2. At the end of this step, there are 3051 predictors left. The resulting dataset are same as the $72\\times 3051$ Golub dataset available online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "golub_train_pp = golub_train_p\n",
    "golub_train_pp[golub_train_pp<100] = 100\n",
    "golub_train_pp[golub_train_pp>16000] = 16000\n",
    "\n",
    "# Filtering\n",
    "golub_filter = function(x, r = 5, d=500){\n",
    "    minval = min(x)\n",
    "    maxval = max(x)\n",
    "    (maxval/minval>r)&&(maxval-minval>d)\n",
    "}\n",
    "index = apply(golub_train_pp, 2, golub_filter)\n",
    "golub_index = (1:7129)[index]\n",
    "golub_train_pp = golub_train_pp[, golub_index]\n",
    "\n",
    "golub_test_pp = golub_test_p\n",
    "golub_test_pp[golub_test_pp<100] = 100\n",
    "golub_test_pp[golub_test_pp>16000] = 16000\n",
    "golub_test_pp = golub_test_pp[, golub_index]\n",
    "\n",
    "# Log Transformation\n",
    "golub_train_p_trans = log10(golub_train_pp)\n",
    "golub_test_p_trans = log10(golub_test_pp)\n",
    "\n",
    "# Normalization\n",
    "train_m = colMeans(golub_train_p_trans)\n",
    "train_sd = apply(golub_train_p_trans, 2, sd)\n",
    "golub_train_p_trans = t((t(golub_train_p_trans)-train_m)/train_sd)\n",
    "golub_test_p_trans  = t((t(golub_test_p_trans)-train_m)/train_sd)\n",
    "golub_train_3051 = golub_train_p_trans\n",
    "golub_train_response = golub_train_r\n",
    "golub_test_3051 = golub_test_p_trans\n",
    "golub_test_response = golub_test_r\n",
    "save(golub_train_3051, golub_train_response, golub_test_3051, golub_test_response, file = \"../transformed data/golub3051.rda\")\n",
    "set.seed(201703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>train</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>  38</td><td>  34</td></tr>\n",
       "\t<tr><td>3051</td><td>3051</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " train & test\\\\\n",
       "\\hline\n",
       "\t   38 &   34\\\\\n",
       "\t 3051 & 3051\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "train | test | \n",
       "|---|---|\n",
       "|   38 |   34 | \n",
       "| 3051 | 3051 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     train test\n",
       "[1,]   38    34\n",
       "[2,] 3051  3051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbind(train = dim(golub_train_p_trans),test = dim(golub_test_p_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Build classifier/predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Step 2(a)**_: Neighbourhood analysis, permutation test and \"signal-to-noise\" ratio calculation: <span style=\"font-size: 0.8em;\">$P(g, c) = (\\mu_{AML}-\\mu_{ALL})/(\\sigma_{AML} + \\sigma_{ALL})$ </span> as in notes 16 and 17. As we can see from the table at the end, neighbourhood analysis further reduce the number of predictors to 740 using 0.01 significant level permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neighbourhood analysis\n",
    "##signal-to-noise ratio/PS in the paper\n",
    "get_p = function(train_d, train_r){\n",
    "    tr_m_aml =  colMeans(train_d[train_r == \"AML\",])\n",
    "    tr_sd_aml = apply(train_d[train_r == \"AML\",], 2, sd)\n",
    "    tr_m_all = colMeans(train_d[train_r == \"ALL\",])\n",
    "    tr_sd_all = apply(train_d[train_r == \"ALL\",], 2, sd)\n",
    "    p = (tr_m_aml-tr_m_all)/(tr_sd_aml+tr_sd_all)\n",
    "    return(p)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nna = matrix(0, 400, 3051)\n",
    "set.seed(201702)\n",
    "# Permutation test\n",
    "for(i in 1:400){\n",
    "    t_r = sample(golub_train_r)\n",
    "    nna[i, ] = get_p(golub_train_p_trans, t_r)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictor selection based on the result of Neighbourhood analysis\n",
    "nna_q = apply(nna, 2, quantile, prob = c(0.005, 0.995))\n",
    "p = get_p(golub_train_p_trans, golub_train_r)\n",
    "# With 0.01 significant level\n",
    "index_1 = (1:3051)[p>=nna_q[2,] | p<=nna_q[1,]]\n",
    "golub_train_p_trans = golub_train_p_trans[, index_1]\n",
    "train_m_aml = colMeans(golub_train_p_trans[golub_train_r == \"AML\",])\n",
    "train_m_all = colMeans(golub_train_p_trans[golub_train_r ==\"ALL\",])\n",
    "golub_test_p_trans =golub_test_p_trans[, index_1]\n",
    "p = p[index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>train</th><th scope=col>test</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 38</td><td> 34</td></tr>\n",
       "\t<tr><td>740</td><td>740</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " train & test\\\\\n",
       "\\hline\n",
       "\t  38 &  34\\\\\n",
       "\t 740 & 740\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "train | test | \n",
       "|---|---|\n",
       "|  38 |  34 | \n",
       "| 740 | 740 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     train test\n",
       "[1,]  38    34 \n",
       "[2,] 740   740 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbind(train = dim(golub_train_p_trans),test = dim(golub_test_p_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Step 2(b)**_: Select the informative 50 genes as in the original paper. We follow the note 18 in selecting the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl_index = c(head(order(p), 25), head(order(p, decreasing = T), 25))\n",
    "p_50 = p[cl_index]\n",
    "b = (train_m_aml[cl_index]+train_m_all[cl_index])/2\n",
    "train_cl = golub_train_p_trans[, cl_index]\n",
    "test_cl = golub_test_p_trans[, cl_index]\n",
    "golub_train_50 = train_cl\n",
    "golub_test_50 = test_cl\n",
    "save(golub_train_50, golub_train_response, golub_test_50, golub_test_response,b, file = \"../transformed data/golub50gene.rda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predict on training and testing data.\n",
    "\n",
    "The prediction steps are the same as in note 18, 19 and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Train_Actual\n",
       "Train_Predict ALL AML\n",
       "    ALL        26   0\n",
       "    AML         0  11\n",
       "    Uncertain   1   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            Test_Actual\n",
       "Test_Predict ALL AML\n",
       "   ALL        19   0\n",
       "   AML         0  12\n",
       "   Uncertain   1   2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train\n",
    "train_vote = t(p_50*t(sweep(train_cl, 2, b)))\n",
    "train_V1 = apply(train_vote, 1, function(x) sum(x[x>0]))\n",
    "train_V2 = abs(apply(train_vote, 1, function(x) sum(x[x<=0])))\n",
    "train_pred = (train_V1-train_V2)/(train_V1+train_V2)\n",
    "train_pred_r = ifelse(abs(train_pred)>0.3, ifelse(train_pred>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table = table(Train_Predict = train_pred_r, Train_Actual = golub_train_r)\n",
    "train_table\n",
    "#test\n",
    "test_vote = t(p_50*t(sweep(test_cl, 2, b)))\n",
    "test_V1 = apply(test_vote, 1, function(x) sum(x[x>0]))\n",
    "test_V2 = abs(apply(test_vote, 1, function(x) sum(x[x<=0])))\n",
    "test_pred = (test_V1-test_V2)/(test_V1+test_V2)\n",
    "test_pred_r = ifelse(abs(test_pred)>0.3, ifelse(test_pred>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table = table(Test_Predict = test_pred_r, Test_Actual = golub_test_r)\n",
    "test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Reproduce result\n",
    "\n",
    "In step 1, data are loaded and preprocessed. However, most details of step 1(c) are not included in the original paper. We combine the information in paper 2, paper 9 and also a reproduce work done by [Robert Gentleman](http://dept.stat.lsa.umich.edu/~ionides/810/gentleman05.pdf), who confirmed in his work the procedure of thresholding and filtering. One also need to notice that we should use the mean and standard deviation in the training data to normalize the testing data as mentioned in the notes of the orignal paper. At the end of step 1, there are 3051 predictors left. The resulting dataset are same as the $72\\times 3051$ Golub dataset available online.\n",
    "\n",
    "In step 2, we first do the neighborhood analysis mentioned in the paper. However, detailed implementation is based on our understanding. (It is basically a permutation test and the seed is set to be 201702.) The method to get the critical values is simplified and hence the bound may be loose. The analysis further reduce the number of predictors, which you can check in the dataset dimensions. We then follow the procedure in the paper and select 50 most related genes as classifiers and subset our train and test data for classification sake. \n",
    "\n",
    "In step 3, we perform the classification or prediction for both training data and testing data. As we can see in the two contigency table, the result is slightly better than in the original paper, since the bootstrap actually have some randomness.\n",
    "\n",
    "**Result Comparison**:\n",
    "_Train Prediction_: In the paper, they correctly classify 36/38 with remaining two as uncertain. We correctly classify 37/38 with one as uncertain.\n",
    "_Test Prediction_: In the paper, they correctly classify 29/34 and we correctly classify 31/34.\n",
    "\n",
    "However, in the original paper, they did leave one out cross validation to get the train accuracy and we didn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare classification with other feature selection method\n",
    "\n",
    "\n",
    "- Based on Paper 3 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_paper3 test_response train_paper3 train_response loaded\n",
    "load(\"../transformed data/paper3.rda\")\n",
    "rbind( Train = dim(train_paper3), Test = dim(test_paper3))\n",
    "\n",
    "\n",
    "train_paper3_aml = colMeans(train_paper3[train_response == \"AML\",])\n",
    "train_paper3_all = colMeans(train_paper3[train_response ==\"ALL\",])\n",
    "b_p3 = (train_paper3_aml+train_paper3_all)/2\n",
    "p_p3 = get_p(train_paper3, train_response)\n",
    "\n",
    "#train\n",
    "train_vote_p3 = t(p_p3*t(sweep(train_paper3, 2, b_p3)))\n",
    "train_V1_p3 = apply(train_vote_p3, 1, function(x) sum(x[x>0]))\n",
    "train_V2_p3 = abs(apply(train_vote_p3, 1, function(x) sum(x[x<=0])))\n",
    "train_pred_p3 = (train_V1_p3-train_V2_p3)/(train_V1_p3+train_V2_p3)\n",
    "train_pred_r_p3 = ifelse(abs(train_pred_p3)>0.3, ifelse(train_pred_p3>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table_p3 = table(Train_Predict = train_pred_r_p3, Train_Actual = train_response)\n",
    "train_table_p3\n",
    "#test\n",
    "test_vote_p3 = t(p_p3*t(sweep(test_paper3, 2, b_p3)))\n",
    "test_V1_p3 = apply(test_vote_p3, 1, function(x) sum(x[x>0]))\n",
    "test_V2_p3 = abs(apply(test_vote_p3, 1, function(x) sum(x[x<=0])))\n",
    "test_pred_p3 = (test_V1_p3-test_V2_p3)/(test_V1_p3+test_V2_p3)\n",
    "test_pred_r_p3 = ifelse(abs(test_pred_p3)>0.3, ifelse(test_pred_p3>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table_p3 = table(Test_Predict = test_pred_r_p3, Test_Actual = test_response)\n",
    "test_table_p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on paper 6 feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_train, pca_test, pls_train, pls_test loaded\n",
    "load(\"../transformed data/paper6.rda\")\n",
    "rbind(Train_pca = dim(pca_train), Test_pca = dim(pca_test), Train_pls = dim(pls_train), Test_pls = dim(pls_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from the table above, paper6 performs dimension reduction and there is only three resulting features(components). However, we could still perform classification using those three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca\n",
    "train_p6_pca_aml = colMeans(pca_train[pca_train$response== \"AML\",-1])\n",
    "train_p6_pca_all = colMeans(pca_train[ pca_train$response==\"ALL\",-1])\n",
    "b_p6_pca = (train_p6_pca_aml+train_p6_pca_all)/2\n",
    "p_p6_pca = get_p(pca_train[, -1], pca_train$response)\n",
    "#train\n",
    "train_vote_p6_pca = t(p_p6_pca*t(sweep(pca_train[, -1], 2, b_p6_pca)))\n",
    "train_V1_p6_pca = apply(train_vote_p6_pca, 1, function(x) sum(x[x>0]))\n",
    "train_V2_p6_pca = abs(apply(train_vote_p6_pca, 1, function(x) sum(x[x<=0])))\n",
    "train_pred_p6_pca = (train_V1_p6_pca-train_V2_p6_pca)/(train_V1_p6_pca+train_V2_p6_pca)\n",
    "train_pred_r_p6_pca = ifelse(abs(train_pred_p6_pca)>0.3, ifelse(train_pred_p6_pca>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table_p6_pca = table(Train_Predict = train_pred_r_p6_pca, Train_Actual = pca_train$response)\n",
    "train_table_p6_pca\n",
    "#test\n",
    "test_vote_p6_pca = t(p_p6_pca*t(sweep(pca_test[, -1], 2, b_p6_pca)))\n",
    "test_V1_p6_pca = apply(test_vote_p6_pca, 1, function(x) sum(x[x>0]))\n",
    "test_V2_p6_pca = abs(apply(test_vote_p6_pca, 1, function(x) sum(x[x<=0])))\n",
    "test_pred_p6_pca = (test_V1_p6_pca-test_V2_p6_pca)/(test_V1_p6_pca+test_V2_p6_pca)\n",
    "test_pred_r_p6_pca = ifelse(abs(test_pred_p6_pca)>0.3, ifelse(test_pred_p6_pca>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table_p6_pca = table(Test_Predict = test_pred_r_p6_pca, Test_Actual = pca_test$response)\n",
    "test_table_p6_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls\n",
    "train_p6_pls_aml = colMeans(pls_train[pls_train$response== \"AML\",-1])\n",
    "train_p6_pls_all = colMeans(pls_train[pls_train$response==\"ALL\",-1])\n",
    "b_p6_pls = (train_p6_pls_aml+train_p6_pls_all)/2\n",
    "p_p6_pls = get_p(pls_train[, -1], pls_train$response)\n",
    "#train\n",
    "train_vote_p6_pls = t(p_p6_pls*t(sweep(pls_train[, -1], 2, b_p6_pls)))\n",
    "train_V1_p6_pls = apply(train_vote_p6_pls, 1, function(x) sum(x[x>0]))\n",
    "train_V2_p6_pls = abs(apply(train_vote_p6_pls, 1, function(x) sum(x[x<=0])))\n",
    "train_pred_p6_pls = (train_V1_p6_pls-train_V2_p6_pls)/(train_V1_p6_pls+train_V2_p6_pls)\n",
    "train_pred_r_p6_pls = ifelse(abs(train_pred_p6_pls)>0.3, ifelse(train_pred_p6_pls>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table_p6_pls = table(Train_Predict = train_pred_r_p6_pls, Train_Actual = pls_train$response)\n",
    "train_table_p6_pls\n",
    "#test\n",
    "test_vote_p6_pls = t(p_p6_pls*t(sweep(pls_test[, -1], 2, b_p6_pls)))\n",
    "test_V1_p6_pls = apply(test_vote_p6_pls, 1, function(x) sum(x[x>0]))\n",
    "test_V2_p6_pls = abs(apply(test_vote_p6_pls, 1, function(x) sum(x[x<=0])))\n",
    "test_pred_p6_pls = (test_V1_p6_pls - test_V2_p6_pls)/(test_V1_p6_pls + test_V2_p6_pls)\n",
    "test_pred_r_p6_pls = ifelse(abs(test_pred_p6_pls)>0.3, ifelse(test_pred_p6_pls>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table_p6_pls = table(Test_Predict = test_pred_r_p6_pls, Test_Actual = pls_test$response)\n",
    "test_table_p6_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on Paper 9 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_BW_predictor test_r train_BW_predictor train_r loaded\n",
    "load(\"../transformed data/paper9.rda\")\n",
    "rbind(Train = dim(train_BW_predictor), Test = dim(test_BW_predictor))\n",
    "\n",
    "train_p9_aml = colMeans(train_BW_predictor[train_r == \"AML\",])\n",
    "train_p9_all = colMeans(train_BW_predictor[train_r ==\"ALL\",])\n",
    "b_p9 = (train_p9_aml+train_p9_all)/2\n",
    "p_p9 = get_p(train_BW_predictor, train_r)\n",
    "\n",
    "#train\n",
    "train_vote_p9 = t(p_p9*t(sweep(train_BW_predictor, 2, b_p9)))\n",
    "train_V1_p9 = apply(train_vote_p9, 1, function(x) sum(x[x>0]))\n",
    "train_V2_p9 = abs(apply(train_vote_p9, 1, function(x) sum(x[x<=0])))\n",
    "train_pred_p9 = (train_V1_p9-train_V2_p9)/(train_V1_p9+train_V2_p9)\n",
    "train_pred_r_p9 = ifelse(abs(train_pred_p9)>0.3, ifelse(train_pred_p9>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table_p9 = table(Train_Predict = train_pred_r_p9, Train_Actual = train_r)\n",
    "train_table_p9\n",
    "#test\n",
    "test_vote_p9 = t(p_p9*t(sweep(test_BW_predictor, 2, b_p9)))\n",
    "test_V1_p9 = apply(test_vote_p9, 1, function(x) sum(x[x>0]))\n",
    "test_V2_p9 = abs(apply(test_vote_p9, 1, function(x) sum(x[x<=0])))\n",
    "test_pred_p9 = (test_V1_p9-test_V2_p9)/(test_V1_p9+test_V2_p9)\n",
    "test_pred_r_p9 = ifelse(abs(test_pred_p9)>0.3, ifelse(test_pred_p9>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table_p9 = table(Test_Predict = test_pred_r_p9, Test_Actual = test_r)\n",
    "test_table_p9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on paper29 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_kmeans train_kmeans golub_test_r golub_train_r loaded\n",
    "load(\"../transformed data/paper29.rda\")\n",
    "rbind(Train = dim(train_kmeans), Test = dim(test_kmeans))\n",
    "\n",
    "train_p29_aml = colMeans(train_kmeans[golub_train_r == \"AML\",])\n",
    "train_p29_all = colMeans(train_kmeans[golub_train_r ==\"ALL\",])\n",
    "b_p29 = (train_p29_aml+train_p29_all)/2\n",
    "p_p29 = get_p(train_kmeans, golub_train_r)\n",
    "\n",
    "#train\n",
    "train_vote_p29 = t(p_p29*t(sweep(train_kmeans, 2, b_p29)))\n",
    "train_V1_p29 = apply(train_vote_p29, 1, function(x) sum(x[x>0]))\n",
    "train_V2_p29 = abs(apply(train_vote_p29, 1, function(x) sum(x[x<=0])))\n",
    "train_pred_p29 = (train_V1_p29-train_V2_p29)/(train_V1_p29+train_V2_p29)\n",
    "train_pred_r_p29 = ifelse(abs(train_pred_p29)>0.3, ifelse(train_pred_p29>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "train_table_p29 = table(Train_Predict = train_pred_r_p29, Train_Actual = golub_train_r)\n",
    "train_table_p29\n",
    "#test\n",
    "test_vote_p29 = t(p_p29*t(sweep(test_kmeans, 2, b_p29)))\n",
    "test_V1_p29 = apply(test_vote_p29, 1, function(x) sum(x[x>0]))\n",
    "test_V2_p29 = abs(apply(test_vote_p29, 1, function(x) sum(x[x<=0])))\n",
    "test_pred_p29 = (test_V1_p29-test_V2_p29)/(test_V1_p29+test_V2_p29)\n",
    "test_pred_r_p29 = ifelse(abs(test_pred_p29)>0.3, ifelse(test_pred_p29>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "test_table_p29 = table(Test_Predict = test_pred_r_p29, Test_Actual = golub_test_r)\n",
    "test_table_p29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the result above,  for paper29 selection, classification result is not as good as others and even a little worse than the bn result in paper29 notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
