{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golub Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppressMessages(library(golubEsets))\n",
    "# data(Golub_Merge)\n",
    "# golub_merge_predict = t(exprs(Golub_Merge))\n",
    "# golub_merge_response =pData(Golub_Merge)[, \"ALL.AML\"]\n",
    "# #Training data predictor and response\n",
    "# data(Golub_Train)\n",
    "# golub_train_predict = t(exprs(Golub_Train))\n",
    "# golub_train_response =pData(Golub_Train)[, \"ALL.AML\"]\n",
    "# #Testing data predictor\n",
    "# data(Golub_Test)\n",
    "# golub_test_predict = t(exprs(Golub_Test))\n",
    "# golub_test_response = pData(Golub_Test)[, \"ALL.AML\"]\n",
    "# save(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response, golub_merge_predict, golub_merge_response, file = \"GolubData.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golub_train_predict, golub_train_response, golub_test_predict, golub_test_response\n",
    "load(\"GolubData.rda\")\n",
    "suppressMessages(library(e1071))\n",
    "suppressMessages(library(fastAdaboost))\n",
    "suppressMessages(library(caret))\n",
    "suppressMessages(library(sparsediscrim))\n",
    "suppressMessages(library(tree))\n",
    "suppressMessages(library(fastAdaboost))\n",
    "suppressMessages(library(bnlearn))\n",
    "library(ropls)\n",
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Selection(PPFS)  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 1\n",
    "## Helper Functions\n",
    "golub_filter = function(x, r = 5, d=500){\n",
    "    minval = min(x)\n",
    "    maxval = max(x)\n",
    "    (maxval/minval>r)&&(maxval-minval>d)\n",
    "}\n",
    "## Neighbourhood analysis\n",
    "### signal-to-noise ratio/PS in the paper\n",
    "get_p = function(train_d, train_r){\n",
    "    tr_m_aml =  colMeans(train_d[train_r == \"AML\",])\n",
    "    tr_sd_aml = apply(train_d[train_r == \"AML\",], 2, sd)\n",
    "    tr_m_all = colMeans(train_d[train_r == \"ALL\",])\n",
    "    tr_sd_all = apply(train_d[train_r == \"ALL\",], 2, sd)\n",
    "    p = (tr_m_aml-tr_m_all)/(tr_sd_aml+tr_sd_all)\n",
    "    return(p)\n",
    "}\n",
    "PPFS1 = function(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response){\n",
    "    \"carry out preprocessing on original Golub data and apply feature selection as both were done in Paper 1; \n",
    "     output is called TransformedData1\"\n",
    "    # Preprocessing\n",
    "    ## Thresholding\n",
    "    golub_train_pp = golub_train_predict\n",
    "    golub_train_pp[golub_train_pp<100] = 100\n",
    "    golub_train_pp[golub_train_pp>16000] = 16000\n",
    "\n",
    "    ## Filtering\n",
    "    index = apply(golub_train_pp, 2, golub_filter)\n",
    "    golub_index = (1:7129)[index]\n",
    "    golub_train_pp = golub_train_pp[, golub_index]\n",
    "\n",
    "    golub_test_pp = golub_test_predict\n",
    "    golub_test_pp[golub_test_pp<100] = 100\n",
    "    golub_test_pp[golub_test_pp>16000] = 16000\n",
    "    golub_test_pp = golub_test_pp[, golub_index]\n",
    "\n",
    "    ## Log Transformation\n",
    "    golub_train_p_trans = log10(golub_train_pp)\n",
    "    golub_test_p_trans = log10(golub_test_pp)\n",
    "\n",
    "    ## Normalization\n",
    "    train_m = colMeans(golub_train_p_trans)\n",
    "    train_sd = apply(golub_train_p_trans, 2, sd)\n",
    "    golub_train_p_trans = t((t(golub_train_p_trans)-train_m)/train_sd)\n",
    "    golub_test_p_trans  = t((t(golub_test_p_trans)-train_m)/train_sd)\n",
    "    golub_train_3051 = golub_train_p_trans\n",
    "    golub_test_3051 = golub_test_p_trans\n",
    "    \n",
    "    # Feature Selection\n",
    "    nna = matrix(0, 400, 3051)\n",
    "    set.seed(201702)\n",
    "    ## Permutation test\n",
    "    for(i in 1:400){\n",
    "        t_r = sample(golub_train_response)\n",
    "        nna[i, ] = get_p(golub_train_p_trans, t_r)\n",
    "    }\n",
    "    \n",
    "    ## Predictor selection based on the result of Neighbourhood analysis\n",
    "    nna_q = apply(nna, 2, quantile, prob = c(0.005, 0.995))\n",
    "    p = get_p(golub_train_p_trans, golub_train_response)\n",
    "    \n",
    "    ## Keep the one with 0.01 significant level\n",
    "    index_1 = (1:3051)[p>=nna_q[2,] | p<=nna_q[1,]]\n",
    "    golub_train_p_trans = golub_train_p_trans[, index_1]\n",
    "    train_m_aml = colMeans(golub_train_p_trans[golub_train_response == \"AML\",])\n",
    "    train_m_all = colMeans(golub_train_p_trans[golub_train_response ==\"ALL\",])\n",
    "    golub_test_p_trans =golub_test_p_trans[, index_1]\n",
    "    p = p[index_1]\n",
    "    \n",
    "    ## 50 most informative genes\n",
    "    cl_index = c(head(order(p), 25), head(order(p, decreasing = T), 25))\n",
    "    p_50 = p[cl_index]\n",
    "    b = (train_m_aml[cl_index]+train_m_all[cl_index])/2\n",
    "    train_cl = golub_train_p_trans[, cl_index]\n",
    "    test_cl = golub_test_p_trans[, cl_index]\n",
    "    golub_train_50 = train_cl\n",
    "    golub_test_50 = test_cl\n",
    "    train_vote = t(p_50*t(sweep(train_cl, 2, b)))\n",
    "    TransformedData1 = list(train_predict = golub_train_50, test_predict = golub_test_50, train_response = golub_train_response, test_response = golub_test_response)\n",
    "    return(TransformedData1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 3\n",
    "## Helper Functions\n",
    "### TNoM score\n",
    "r_score = function(slabel){\n",
    "    total = length(slabel)\n",
    "    n = sum(slabel == 0) \n",
    "    p = sum(slabel == 1) \n",
    "    temp = min(n, p)\n",
    "    d = ifelse(n < p, 1, -1)\n",
    "    for(i in 1:(total-1)){\n",
    "        count = sum(slabel[1:i] == 0)\n",
    "        t_t = min(n-2*count+i, p+2*count-i)\n",
    "        t_d = ifelse((n-2*count+i)<(p+2*count-i),1,-1)\n",
    "        if(t_t < temp){\n",
    "            temp = t_t\n",
    "            d = t_d\n",
    "        }\n",
    "    }\n",
    "    c(temp, t_d)\n",
    "}\n",
    "\n",
    "### Significance (using bootstrap with size 1000 to replace)\n",
    "r_bootstrap = function(gene, label){\n",
    "    total = length(label)\n",
    "    index = order(gene)\n",
    "    s_l = label[index]\n",
    "    score= r_score(s_l)\n",
    "    dist_score = numeric(200)\n",
    "    for(i in 1:200){\n",
    "        temp = sample(1:total)\n",
    "        t = r_score(label[temp])\n",
    "        dist_score[i] = t[1]\n",
    "    }\n",
    "    prob = mean(dist_score<score[1])\n",
    "    c(score[1], score[2], prob)\n",
    "}\n",
    "\n",
    "PPFS3 = function(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response){\n",
    "    \"carry out preprocessing on original Golub data and apply feature selection as both were done in Paper 3; \n",
    "    output is called TransformedData3\"\n",
    "    golub_train_l = ifelse(golub_train_response == \"AML\", 1, 0)\n",
    "    golub_test_l = ifelse(golub_test_response == \"AML\", 1, 0)\n",
    "    set.seed(201703)\n",
    "    # perform the caculation, this may take a while since the inevitable loops in above functions\n",
    "    a = apply(golub_train_predict, 2, r_bootstrap, label = golub_train_l)\n",
    "    # select informative genes and subset the train and test data\n",
    "    index = (1:7129)[a[1,]<14 & a[3,]<0.01]\n",
    "    b = order(a[1,index])[1:50]\n",
    "    \n",
    "    # data subsetting\n",
    "    train_cl = golub_train_predict[, index]\n",
    "    test_cl = golub_test_predict[, index]\n",
    "    train_paper3 = train_cl[, b]\n",
    "    test_paper3 = test_cl[, b]\n",
    "    TransformedData3 = list(train_predict = train_paper3, test_predict = test_paper3, train_response = golub_train_response, test_response = golub_test_response)\n",
    "    return(TransformedData3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 6\n",
    "\n",
    "PPFS6PCA = function(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response, K = 3){\n",
    "    \"carry out preprocessing on original Golub data and apply PCA feature selection as both were done in Paper 6; \n",
    "    output is called TransformedData6PCA\"\n",
    "    # First Same 50 genes as in PPFS1\n",
    "    rslt = PPFS1(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response)\n",
    "    golub_train_p = rslt$train_predict\n",
    "    golub_train_r = rslt$train_response\n",
    "    golub_test_p = rslt$test_predict\n",
    "    golub_test_r = rslt$test_response\n",
    "    pca_rslt= getLoadingMN(opls(golub_train_p, printL = F, predI = K))\n",
    "    pca_train_s = t(t(pca_rslt)%*%t(golub_train_p))\n",
    "    pca_test_s = t(t(pca_rslt)%*%t(golub_test_p))\n",
    "    TransformedData6PCA = list(train_predict = pca_train_s, test_predict = pca_test_s, train_response = golub_train_r, test_response = golub_test_r)\n",
    "    return(TransformedData6PCA)\n",
    "}\n",
    "\n",
    "PPFS6PLS =  function(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response, K = 3){\n",
    "    \"carry out preprocessing on original Golub data and apply PLS feature selection as both were done in Paper 6; \n",
    "    output is called TransformedData6PLS\"\n",
    "    # First Same 50 genes as in PPFS1\n",
    "    rslt = PPFS1(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response)\n",
    "    golub_train_p = rslt$train_predict\n",
    "    golub_train_r = rslt$train_response\n",
    "    golub_test_p = rslt$test_predict\n",
    "    golub_test_r = rslt$test_response\n",
    "    pls_rslt = getLoadingMN(opls(golub_train_p, golub_train_r, printL = F, predI = K))\n",
    "    pls_train_s = t(t(pls_rslt)%*%t(golub_train_p))\n",
    "    pls_test_s = t(t(pls_slt)%*%t(golub_test_p))\n",
    "    TransformedData6PLS = list(train_predict = pls_train_s, test_predict = pls_test_s, train_response = golub_train_r, test_response = golub_test_r)\n",
    "    return(TransformedData6PLS)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 9\n",
    "## Helper Function\n",
    "### Split train test as specified in the paper\n",
    "mysplit = function(n){\n",
    "    sample(1:n, floor(n/3))\n",
    "}\n",
    "\n",
    "### implement function for calculating BW as stated in the paper(the ratio of between-group to within group sums of squares)\n",
    "BW = function(predictor, response){\n",
    "    overall = colMeans(predictor)\n",
    "    ALL_mean = apply(predictor, 2, function(x) mean(x[response == \"ALL\"]))\n",
    "    AML_mean = apply(predictor, 2, function(x) mean(x[response == \"AML\"]))\n",
    "    numerator = sum(response == \"ALL\")*(ALL_mean-overall)^2+sum(response == \"AML\")*(AML_mean-overall)^2\n",
    "    denumerator = colSums((t(t(predictor[response == \"ALL\", ])-ALL_mean))^2)+colSums((t(t(predictor[response == \"AML\", ])-AML_mean))^2)\n",
    "    numerator/denumerator\n",
    "}\n",
    "                     \n",
    "PPFS9 =  function(golub_merge_predict, golub_merge_response, K = 3, set_seed = TRUE){\n",
    "    \"carry out preprocessing on original Golub data and apply feature selection as both were done in Paper 9; \n",
    "    output is called TransformedData9\"\n",
    "    golub_merge_l = ifelse(golub_merge_response == \"AML\", 1, 0)\n",
    "    # \n",
    "    ## Thresholding\n",
    "    golub_merge_pp = golub_merge_predict\n",
    "    golub_merge_pp[golub_merge_pp<100] = 100\n",
    "    golub_merge_pp[golub_merge_pp>16000] = 16000\n",
    "\n",
    "    merge_index = apply(golub_merge_pp, 2, golub_filter)\n",
    "    golub_merge_index = (1:7129)[merge_index]\n",
    "    golub_merge_pp = golub_merge_pp[, golub_merge_index]\n",
    "    \n",
    "    ## Base 10 logarithmic transformation\n",
    "    golub_merge_p_trans = log10(golub_merge_pp)\n",
    "    # Further standardization to mean 0 variance 1.\n",
    "    scale_golub_merge = scale(golub_merge_p_trans)\n",
    "    if(set_seed == TRUE){\n",
    "        set.seed(201703)\n",
    "    }\n",
    "    # randomly feature select once for comparison for furthur study\n",
    "    id = mysplit(nrow(scale_golub_merge))\n",
    "    train_p = scale_golub_merge[-id,]\n",
    "    train_r = golub_merge_response[-id]\n",
    "    test_p = scale_golub_merge[id,]\n",
    "    test_r = golub_merge_response[id]\n",
    "    temp_bw = order(BW(train_p, train_r), decreasing = T)[1:50]\n",
    "    train_BW_predictor = train_p[,temp_bw]\n",
    "    test_BW_predictor = test_p[,temp_bw]\n",
    "    TransformedData9 = list(train_predict = train_BW_predictor, test_predict = test_BW_predictor, train_response = train_r, test_response = test_r)\n",
    "    return(TransformedData9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 29\n",
    "## Helper Function\n",
    "### SNR: signal-to-noise ratio\n",
    "get_SNR = function(train_d, train_r){\n",
    "    tr_m_aml =  colMeans(train_d[train_r == \"AML\",])\n",
    "    tr_sd_aml = apply(train_d[train_r == \"AML\",], 2, sd)\n",
    "    tr_m_all = colMeans(train_d[train_r == \"ALL\",])\n",
    "    tr_sd_all = apply(train_d[train_r == \"ALL\",], 2, sd)\n",
    "    p = (tr_m_aml-tr_m_all)/(tr_sd_aml+tr_sd_all)\n",
    "    return(p)\n",
    "}\n",
    "### Kmeans clustering and then SNR ranking selection\n",
    "get_kmeans = function(k, train_d, train_r){\n",
    "    cl = kmeans(t(train_d), k, iter.max=50)$cluster\n",
    "    result = numeric(k)\n",
    "    for(i in 1:k){\n",
    "        id = (cl == i)\n",
    "        oid = (1:ncol(train_d))[id]\n",
    "        iSNR = get_SNR(t(t(train_d)[id,]),train_r)\n",
    "        temp = which.max(abs(iSNR))\n",
    "        result[i] = oid[temp]\n",
    "    }\n",
    "    return(result)\n",
    "}\n",
    "PPFS29 = function(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response, K = 50){\n",
    "    \"carry out preprocessing on original Golub data and apply feature selection as both were done in Paper 29;\n",
    "    output is called TransformedData29\"\n",
    "    # Thresholding\n",
    "    golub_train_pp = golub_train_predict\n",
    "    golub_train_pp[golub_train_pp<100] = 100\n",
    "    golub_train_pp[golub_train_pp>16000] = 16000\n",
    "\n",
    "    # Filtering\n",
    "    index = apply(golub_train_pp, 2, golub_filter)\n",
    "    golub_index = (1:7129)[index]\n",
    "    golub_train_pp = golub_train_pp[, golub_index]\n",
    "\n",
    "    golub_test_pp = golub_test_predict\n",
    "    golub_test_pp[golub_test_pp<100] = 100\n",
    "    golub_test_pp[golub_test_pp>16000] = 16000\n",
    "    golub_test_pp = golub_test_pp[, golub_index]\n",
    "\n",
    "    # Log Transformation\n",
    "    golub_train_p_trans = log10(golub_train_pp)\n",
    "    golub_test_p_trans = log10(golub_test_pp)\n",
    "\n",
    "    # Normalization\n",
    "    train_m = colMeans(golub_train_p_trans)\n",
    "    train_sd = apply(golub_train_p_trans, 2, sd)\n",
    "    golub_train_p_trans = t((t(golub_train_p_trans)-train_m)/train_sd)\n",
    "    golub_test_p_trans  = t((t(golub_test_p_trans)-train_m)/train_sd)\n",
    "\n",
    "    kmeans_id = get_kmeans(K, golub_train_p_trans, golub_train_response)\n",
    "    train_kmeans = golub_train_p_trans[,kmeans_id]\n",
    "    test_kmeans = golub_test_p_trans[,kmeans_id]\n",
    "    TransformedData29 = list(train_predict = train_kmeans, test_kmeans = test_kmeans, train_response = golub_train_response, test_response = golub_test_response)\n",
    "    return(TransformedData29)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model/Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 1\n",
    "## Helper function \n",
    "get_p = function(train_d, train_r){\n",
    "    tr_m_aml =  colMeans(train_d[train_r == \"AML\",])\n",
    "    tr_sd_aml = apply(train_d[train_r == \"AML\",], 2, sd)\n",
    "    tr_m_all = colMeans(train_d[train_r == \"ALL\",])\n",
    "    tr_sd_all = apply(train_d[train_r == \"ALL\",], 2, sd)\n",
    "    p = (tr_m_aml-tr_m_all)/(tr_sd_aml+tr_sd_all)\n",
    "    return(p)\n",
    "}\n",
    "classifier1 = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out classification as in Paper 1; \n",
    "     output is called Rates1 and is the value in row 1, column_i \n",
    "     call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 1\"\n",
    "    train_m_aml = colMeans(train_p[train_r == \"AML\",])\n",
    "    train_m_all = colMeans(train_p[train_r ==\"ALL\",])\n",
    "    b = (train_m_aml+train_m_all)/2\n",
    "    p = get_p(train_p, train_r)\n",
    "    #train\n",
    "    train_vote = t(p*t(sweep(train_p, 2, b)))\n",
    "    train_V1 = apply(train_vote, 1, function(x) sum(x[x>0]))\n",
    "    train_V2 = abs(apply(train_vote, 1, function(x) sum(x[x<=0])))\n",
    "    train_pred = (train_V1-train_V2)/(train_V1+train_V2)\n",
    "    train_pred_r = ifelse(abs(train_pred)>0.3, ifelse(train_pred>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "    train_table = table(Train_Predict = train_pred_r, Train_Actual = train_r)\n",
    "    ##train_table\n",
    "    #test\n",
    "    test_vote = t(p*t(sweep(test_p, 2, b)))\n",
    "    test_V1 = apply(test_vote, 1, function(x) sum(x[x>0]))\n",
    "    test_V2 = abs(apply(test_vote, 1, function(x) sum(x[x<=0])))\n",
    "    test_pred = (test_V1-test_V2)/(test_V1+test_V2)\n",
    "    test_pred_r = ifelse(abs(test_pred)>0.3, ifelse(test_pred>0, \"AML\", \"ALL\"), \"Uncertain\")\n",
    "    test_table = table(Test_Predict = test_pred_r, Test_Actual = test_r)\n",
    "    ##test accuracy rate\n",
    "    Rates1 = mean(test_pred_r == test_r)\n",
    "    return(Rates1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 3\n",
    "## NN\n",
    "### helper function\n",
    "cl_nn_helper = function(new_s, train, train_label){\n",
    "    # use Pearson correlation\n",
    "    corr = apply(train, 1, cor, new_s)\n",
    "    train_label[corr==max(corr)]\n",
    "}\n",
    "\n",
    "classifier3nn = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out NN classification as in Paper 3;\n",
    "    output is called Rates3NN and is the value in row 2, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 2\"\n",
    "    nn_test_pr_p1 = apply(test_p,1, cl_nn_helper, train_p, train_r)\n",
    "    Rates3NN = mean(nn_test_pr_pl, test_r)\n",
    "    return(Rates3NN)\n",
    "}\n",
    "\n",
    "## Linear SVM\n",
    "classifier3lsvm = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out linear SVM classification as in Paper 3;\n",
    "    output is called Rates3LSVM and is the value in row 3, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 3\"\n",
    "    r_train = data.frame(train_p, Y = factor(train_r))\n",
    "    r_test =data.frame( test_p, Y = factor(test_r))\n",
    "    svm_linear = svm(Y~., data = r_train)\n",
    "    svm_l_tepr = predict(svm_linear, newdata = r_test)\n",
    "    Rates3LSVM = mean(svm_l_tepr == test_r)\n",
    "    return(Rates3LSVM)\n",
    "}\n",
    "\n",
    "## Polynomial SVM\n",
    "classifier3qsvm = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out polynomial degree 2 SVM classification as in Paper 3;\n",
    "    output is called Rates3PSVM and is the value in row 4, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 4\"\n",
    "    r_train = data.frame(train_p, Y = factor(train_r))\n",
    "    r_test =data.frame( test_p, Y = factor(test_r))\n",
    "    svm_quad = svm(Y~., data = r_train, kernel = \"polynomial\", degree = 2,  gamma =0.01, coef0 = 100)\n",
    "    svm_q_tepr = predict(svm_quad, newdata = r_test)\n",
    "    Rates3PSVM = mean(svm_q_tepr == r_test)\n",
    "    return(Rates3PSVM)\n",
    "}\n",
    "\n",
    "## Adaboost\n",
    "\n",
    "classifier3Ada = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out Adaboost classification as in Paper 3;\n",
    "    output is called Rates3Ada and is the value in row 5, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 5\"\n",
    "    r_train_p1 = data.frame(train_p, Y = factor(train_r))\n",
    "    r_test_p1 =data.frame( test_p, Y = factor(test_r))\n",
    "    ada_cl_p1 = adaboost(Y~., data = r_train_p1, 100)\n",
    "    ada_test_pr_p1 = predict(ada_cl_p1, newdata = r_test_p1)\n",
    "    Rates3Ada = mean(ada_test_pr_pl == test_r)\n",
    "    return(Rates3Ada)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 6\n",
    "classifier6logit = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out Logistic Discrimination as in Paper 6;\n",
    "    output is called Rates6Logit and is the value in row 6, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 6\"\n",
    "    train_data = data.frame(response = train_r, train_p)\n",
    "    test_data = test_p\n",
    "    ld_s = train(response~., data = train_data, method = \"glm\", family = \"binomial\", trControl = trainControl(method = \"LOOCV\"))\n",
    "    ld_te = predict(ld_s, data.frame(test_data))\n",
    "    Rates6Logit = mean(ld_te == test_r)\n",
    "    return(Rates6Logit)\n",
    "}\n",
    "classifier6qda = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out QDA as in Paper 6;\n",
    "    output is called Rates6QDA and is the value in row 7, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 7\"\n",
    "    train_data = data.frame(response = train_r, train_p)\n",
    "    test_data = test_p\n",
    "    qda_s = train(response~., data = train_data, method = \"qda\",  trControl = trainControl(method = \"LOOCV\"))\n",
    "    qda_te = predict(qda_s, data.frame(test_data))\n",
    "    Rates6QDA = mean(qda_te == test_r)\n",
    "    return(Rates6QDA)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 9\n",
    "\n",
    "## NN\n",
    "### Distance measure used in the paper\n",
    "Distance = function(predictor, test){\n",
    "    1- apply(predictor, 1, cor, test)\n",
    "}\n",
    "### NN classification process\n",
    "paper9_nn = function(test, pk, learning, response){\n",
    "     distance = Distance(learning, test)\n",
    "     index = order(distance)[1:pk]\n",
    "     cl = ifelse(sum(response[index] == \"AML\")>sum(response[index]==\"ALL\"), \"AML\", \"ALL\")\n",
    "     cl\n",
    "}\n",
    "# leave-one-cross-validation to tune k\n",
    "mycv= function(pk,learning,response){\n",
    "    error = 0\n",
    "    for(i in 1:nrow(learning)){\n",
    "        cl = paper9_nn(learning[i,], pk, learning[-i, ], response[-i])\n",
    "        error = error+(cl == response[i])\n",
    "    }\n",
    "    error\n",
    "}\n",
    "classifier9nn = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out Nearest Neighbor as in Paper 9;\n",
    "    output is called Rates9NN and is the value in row 8, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 8\"\n",
    "    k = seq(1, 21, 2)\n",
    "    choose_k = sapply(k,mycv, learning = train_p, response= train_r)\n",
    "    nn_test = apply(test_p ,1, paper9_nn, k[which.min(choose_k)], train_p ,train_r)\n",
    "    Rates9NN = mean(nn_test == test_r)\n",
    "    return(Rates9NN)\n",
    "}\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "### test_paper3 test_response train_paper3 train_response loaded\n",
    "classifier9dt = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out Decision Tree as in Paper 9;\n",
    "    output is called Rates9DT and is the value in row 9, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 9\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    tree_mdl = tree(response~.,data = cbine_data)\n",
    "    tree_te = predict(tree_mdl, data.frame(test_p), type = \"class\")\n",
    "    Rates9DT = mean(tree_te == test_r)\n",
    "    return(Rates9DT)\n",
    "}\n",
    "\n",
    "## Bagging\n",
    "\n",
    "my_baghelper = function(train, test){\n",
    "    bg = sample(nrow(train), replace = T)\n",
    "    temp_md = tree(response~., data = train[bg, ])\n",
    "    predict(temp_md, test, type = \"class\")\n",
    "}\n",
    "classifier9bg = function(train_p, train_r, test_p, test_r, B = 50){\n",
    "    \"carry out Bagging as in Paper 9;\n",
    "    output is called Rates9BG and is the value in row 10, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 10\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    t_te = replicate(B, my_baghelper(cbine_data, data.frame(test_p)))\n",
    "    pred_te = apply(t_te, 1, function(x) ifelse(sum(x == \"AML\")>sum(x ==\"ALL\"), \"AML\", \"ALL\"))\n",
    "    Rates9BG = mean(pred_te == test_r)\n",
    "    return(Rates9BG)\n",
    "}\n",
    "                    \n",
    "## Bagging with CPD\n",
    "                    \n",
    "CPD = function(x1, x2, d = 0.75){\n",
    "    a = runif(nrow(x1), 0, d)\n",
    "    a*x1+(1-a)*x2\n",
    "}\n",
    "### helper function for each bagging with CPD\n",
    "my_cpdhelper = function(train, test){\n",
    "    id1 = sample(nrow(train), replace = T)\n",
    "    id2 = sample(nrow(train), replace = T)\n",
    "    temp = CPD(train[id1, -1], train[id2,-1])\n",
    "    temp_md = tree(response~., data = data.frame(temp, response = train$response[id1]))\n",
    "    predict(temp_md, test, type = \"class\")\n",
    "}\n",
    "classifier9bgcpd = function(train_p, train_r, test_p, test_r, B = 50){\n",
    "    \"carry out Bagging with CPD as in Paper 9;\n",
    "    output is called Rates9BGCPD and is the value in row 11, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 11\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    t_te = replicate(B, my_cpdhelper(cbine_data, data.frame(test_p)))\n",
    "    pred_te = apply(t_te, 1, function(x) ifelse(sum(x == \"AML\")>sum(x ==\"ALL\"), \"AML\", \"ALL\"))\n",
    "    Rates9BGCPD = mean(pred_te == test_r)\n",
    "    return(Rates9BGCPD)\n",
    "}\n",
    "                    \n",
    "## FLDA\n",
    "classifier9flda = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out FLDA as in Paper 9;\n",
    "    output is called Rates9FLDA and is the value in row 12, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 12\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    flda_md = MASS::lda(response~., data = cbine_data)\n",
    "    flda_te = predict(flda_md, data.frame(test_p))$class\n",
    "    Rates9FLDA = mean(flda_te == test_r)\n",
    "    return(Rates9FLDA)\n",
    "}\n",
    "  \n",
    "## DLDA\n",
    "                    \n",
    "classifier9dlda = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out DLDA as in Paper 9;\n",
    "    output is called Rates9DLDA and is the value in row 13, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 13\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    dlda_md = dlda(response~., data = cbine_data)\n",
    "    dlda_te = predict(dlda_md, data.frame(test_p))$class\n",
    "    Rates9DLDA = mean(dlda_te == test_r)\n",
    "    return(Rates9DLDA)\n",
    "}\n",
    "                    \n",
    "## DQDA                    \n",
    "classifier9dqda = function(train_p, train_r, test_p, test_r){\n",
    "    \"carry out DQDA as in Paper 9;\n",
    "    output is called Rates9DQDA and is the value in row 14, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 14\"\n",
    "    cbine_data = data.frame(response = factor(train_r), train_p)\n",
    "    dqda_md = dlda(response~., data = cbine_data)\n",
    "    dqda_te = predict(dqda_md, data.frame(test_p))$class\n",
    "    Rates9DQDA = mean(dqda_te == test_r)\n",
    "    return(Rates9DQDA)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper 29\n",
    "classifier29 = function(train_p, train_r, test_p, test_r, B = 50){\n",
    "    \"carry out Bayesian Network as in Paper 29;\n",
    "    output is called Rates29BN and is the value in row 15, column_i\n",
    "    call this function 6 times using every TransformedData_i as input in turn to get a 1x6 output for row 15\"\n",
    "    train_data = data.frame(train_p, class = train_r)\n",
    "    test_data = data.frame(test_p)\n",
    "    eg = empty.graph(c(\"class\", colnames(train_p)))\n",
    "    arcs(eg) = matrix(c(rep(\"class\", 50), \n",
    "                        colnames(train_p)), \n",
    "                      ncol = 2, byrow = F, \n",
    "                      dimnames = list(c(), c(\"from\", \"to\")))\n",
    "    fitted = bn.fit(eg, train_data)\n",
    "    predict_te = predict(fitted, node = \"class\", method=\"bayes-lw\", test_data)\n",
    "    Rates29BN = mean(predict_te == test_r)\n",
    "    return(Rates29BN)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.911764705882353"
      ],
      "text/latex": [
       "0.911764705882353"
      ],
      "text/markdown": [
       "0.911764705882353"
      ],
      "text/plain": [
       "[1] 0.9117647"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example for calculating Column 1, Row 1, which is Paper1 Selection, Paper1 Classifier.\n",
    "Paper1Selection = PPFS1(golub_train_predict, golub_train_response, golub_test_predict, golub_test_response)\n",
    "Cell11 = classifier1(Paper1Selection$train_predict, Paper1Selection$train_response, Paper1Selection$test_predict, Paper1Selection$test_response)\n",
    "Cell11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1\n",
    "||Paper1 Selection|Paper3 Selection|Paper6 PCA Selection|Paper6 PLS Selection|Paper9 Selection|Paper29 Selection|\n",
    "|---|---|------|------|------|-------|------|\n",
    "|Paper1 classifiier|0.912|0.941|0.971|0.971|0.958|0.706|\n",
    "|Paper 3 NN|0.971|0.941|0.912|0.941|1|0.912|\n",
    "|Paper 3 SVM Linear|0.971|0.971|0.941|0.971|1|0.765|\n",
    "|Paper 3 SVM Quadratic|0.971|0.882|0.971|0.971|1|0.912|\n",
    "|Paper 3 Adaboost|0.912|0.912|0.971|0.971|0.958|0.941|\n",
    "|Paper 6 logit|0.971|0.971|0.971|0.971|1|0.853|\n",
    "|Paper 6 qda|0.941|0.912|0.941|0.971|1|0.853|\n",
    "|Paper 9 nn |0.971|0.912|0.853|0.971|0.958|0.971|\n",
    "|Paper 9 decision tree|0.912|0.912|0.971|0.971|0.917|0.735|\n",
    "|Paper 9 bagging|0.971|0.912|0.971|0.971|0.958|0.735|\n",
    "|Paper 9 bagging with CPD|0.941|0.912|0.971|0.971|0.917|0.794|\n",
    "|Paper 9 FLDA|0.912|0.912|0.971|0.971|0.958|0.794|\n",
    "|Paper 9 DLDA|0.941|0.912|0.971|0.971|0.958|0.765|\n",
    "|Paper 9 DQDA|0.912|0.912|0.971|0.971|0.958|0.735|\n",
    "|Paper 29 Bayesian Network|0.735|0.882|0.971|0.971|1|0.647|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
